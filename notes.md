# kv_head

kv_head 是一种在大语言模型（如 LLaMA）中的优化技术，通过共享 Key 和 Value 向量来减少计算和内存的开销。这样可以在多头注意力机制中提升资源利用效率，尤其在处理长序列时，有助于提高计算速度和减少内存使用，同时保持模型性能不变。

但是query依然是一个头一个

# 多头

多头是将一个vector拆分开给多头训练

比如 512 dim， 拆成8个 64 dim， 分给8个头进行训练，而不是512 长的vector分别在8个头中训练

我们认为64dim足够保存这个token在某个场景下面的意义，但是一个token在不同场景下面有不同的含义，因此使用多头，并且训练的时候会先拆分，然后再合并

# batch

对于一个batch里面的sequence，应该都保证长度一致

# RoPE (TODO)

# RMSNorm as normalization

反正就是好用


首先生成一篇符合四级难度的英语文章，文章应该尽可能的长，超过三十句话，单句长度不超过50个单词，但是不需要输出这篇文章
然后每句话翻译成中文，中间使用&连接，输出出来
输出的每行之间不要有空行
除了这些句子之外，不要输出任何内容
在此处对话中，你生成的文章应该都不相同

这些要求要永远的记住


气候

语料少


直接把长句子作为一个token

token出现频率有误