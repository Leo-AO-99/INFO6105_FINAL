# kv_head

kv_head 是一种在大语言模型（如 LLaMA）中的优化技术，通过共享 Key 和 Value 向量来减少计算和内存的开销。这样可以在多头注意力机制中提升资源利用效率，尤其在处理长序列时，有助于提高计算速度和减少内存使用，同时保持模型性能不变。

但是query依然是一个头一个

# 多头

多头是将一个vector拆分开给多头训练

比如 512 dim， 拆成8个 64 dim， 分给8个头进行训练，而不是512 长的vector分别在8个头中训练

我们认为64dim足够保存这个token在某个场景下面的意义，但是一个token在不同场景下面有不同的含义，因此使用多头，并且训练的时候会先拆分，然后再合并

# batch

对于一个batch里面的sequence，应该都保证长度一致

# RoPE (TODO)

# RMSNorm as normalization

反正就是好用